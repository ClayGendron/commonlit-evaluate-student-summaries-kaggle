{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoConfig, AutoTokenizer\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dir = Path(os.getcwd())\n",
    "kaggle_dir = Path('/kaggle/input')\n",
    "\n",
    "notebook_dir = local_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(notebook_dir / 'commonlit-evaluate-student-summaries' / 'summaries_train.csv')\n",
    "train_prompts_df = pd.read_csv(notebook_dir / 'commonlit-evaluate-student-summaries' / 'prompts_train.csv')\n",
    "train_df = train_df.merge(train_prompts_df, on='prompt_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Prediction Model (DeBERTa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, prompt_title):\n",
    "    \"\"\"Split data into training and validation sets based on prompt_title\"\"\"\n",
    "    training_df = df[df['prompt_title'] != prompt_title]\n",
    "    validation_df = df[df['prompt_title'] == prompt_title]\n",
    "    return training_df, validation_df\n",
    "\n",
    "def prepare_data(df, tokenizer, batch_size, shuffle):\n",
    "    \"\"\"Prepare data into DataLoader for training and validation\"\"\"\n",
    "    responses = df['text'].to_list()\n",
    "    content = df['content'].to_list()\n",
    "    wording = df['wording'].to_list()\n",
    "    \n",
    "    encodings = tokenizer(responses, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "    content_tensor = torch.tensor(content).unsqueeze(-1).float()\n",
    "    wording_tensor = torch.tensor(wording).unsqueeze(-1).float()\n",
    "    dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'], content_tensor, wording_tensor)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    return loader\n",
    "\n",
    "def compute_metrics(eval_predictions):\n",
    "    mse_loss_fn = MSELoss()\n",
    "    logits, labels = eval_predictions\n",
    "    content_logits, wording_logits = logits[:, 0], logits[:, 1]\n",
    "    content_labels, wording_labels = labels[:, 0], labels[:, 1]\n",
    "    \n",
    "    content_mse = mse_loss_fn(content_logits, content_labels).item()\n",
    "    wording_mse = mse_loss_fn(wording_logits, wording_labels).item()\n",
    "    \n",
    "    avg_mse = (content_mse + wording_mse) / 2\n",
    "    \n",
    "    return {'content_mse': content_mse, 'wording_mse': wording_mse, 'avg_mse': avg_mse}\n",
    "\n",
    "def train_transformer(model_path, training_loader, validation_loader, device, lr=1e-5, weight_decay=0.01, epochs=25):\n",
    "    \"\"\"Train transformer model using HuggingFace's Trainer\"\"\"\n",
    "    \n",
    "    print(f'Loading model from {model_path}...')\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "    model.to(device)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        per_device_train_batch_size=training_loader.batch_size,\n",
    "        per_device_eval_batch_size=validation_loader.batch_size,\n",
    "        evaluation_strategy='epoch',\n",
    "        learning_rate=lr,\n",
    "        weight_decay=weight_decay,\n",
    "        num_train_epochs=epochs,\n",
    "        output_dir='./training_output',\n",
    "        logging_dir='./training_logs',\n",
    "        logging_steps=1,\n",
    "        save_strategy='epoch',\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='avg_mse',\n",
    "        greater_is_better=False,\n",
    "        push_to_hub=False,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=training_loader.dataset,\n",
    "        eval_dataset=validation_loader.dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    metrics = trainer.evaluate()\n",
    "    print(f'Training complete. Final validation MSE: {metrics[\"avg_mse\"]}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train RoBERTa Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = notebook_dir / 'deberta-grader'\n",
    "device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    temp_model = AutoModelForSequenceClassification.from_pretrained('microsoft/deberta-v3-base', num_labels=2)\n",
    "    temp_model.save_pretrained(model_path)\n",
    "\n",
    "deberta_model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "deberta_tozenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base', model_max_length=1024)\n",
    "\n",
    "deberta_config = AutoConfig.from_pretrained(model_path)\n",
    "deberta_config.max_position_embeddings = 1024\n",
    "deberta_config.hidden_dropout_prob = 0.2\n",
    "deberta_config.attention_probs_dropout_prob = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, validation_df = split_data(train_df, 'The Third Wave')\n",
    "\n",
    "training_loader = prepare_data(\n",
    "    training_df, \n",
    "    deberta_tozenizer, \n",
    "    batch_size=8, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_loader = prepare_data(\n",
    "    validation_df, \n",
    "    deberta_tozenizer, \n",
    "    batch_size=8, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from c:\\Users\\c.gendron1\\Git\\commonlit-evaluate-student-summaries-kaggle\\deberta-grader...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537b890451cd40d494583cb3df0a6257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "vars() argument must have __dict__ attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\c.gendron1\\Git\\commonlit-evaluate-student-summaries-kaggle\\model_training.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/c.gendron1/Git/commonlit-evaluate-student-summaries-kaggle/model_training.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m deberta_model \u001b[39m=\u001b[39m train_transformer(model_path, training_loader, validation_loader, device, lr\u001b[39m=\u001b[39;49m\u001b[39m1e-5\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\c.gendron1\\Git\\commonlit-evaluate-student-summaries-kaggle\\model_training.ipynb Cell 10\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/c.gendron1/Git/commonlit-evaluate-student-summaries-kaggle/model_training.ipynb#X32sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/c.gendron1/Git/commonlit-evaluate-student-summaries-kaggle/model_training.ipynb#X32sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/c.gendron1/Git/commonlit-evaluate-student-summaries-kaggle/model_training.ipynb#X32sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/c.gendron1/Git/commonlit-evaluate-student-summaries-kaggle/model_training.ipynb#X32sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/c.gendron1/Git/commonlit-evaluate-student-summaries-kaggle/model_training.ipynb#X32sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/c.gendron1/Git/commonlit-evaluate-student-summaries-kaggle/model_training.ipynb#X32sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/c.gendron1/Git/commonlit-evaluate-student-summaries-kaggle/model_training.ipynb#X32sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/c.gendron1/Git/commonlit-evaluate-student-summaries-kaggle/model_training.ipynb#X32sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/c.gendron1/Git/commonlit-evaluate-student-summaries-kaggle/model_training.ipynb#X32sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m metrics \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mevaluate()\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\transformers\\trainer.py:1591\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1589\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1590\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1591\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1592\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1593\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1594\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1595\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1596\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\transformers\\trainer.py:1870\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1867\u001b[0m     rng_to_sync \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m step \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m-> 1870\u001b[0m \u001b[39mfor\u001b[39;00m step, inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(epoch_iterator):\n\u001b[0;32m   1871\u001b[0m     total_batched_samples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1872\u001b[0m     \u001b[39mif\u001b[39;00m rng_to_sync:\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\accelerate\\data_loader.py:384\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[39m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 384\u001b[0m     current_batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(dataloader_iter)\n\u001b[0;32m    385\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     \u001b[39myield\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\transformers\\trainer_utils.py:737\u001b[0m, in \u001b[0;36mRemoveColumnsCollator.__call__\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, features: List[\u001b[39mdict\u001b[39m]):\n\u001b[0;32m    736\u001b[0m     features \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_remove_columns(feature) \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m features]\n\u001b[1;32m--> 737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_collator(features)\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\transformers\\data\\data_collator.py:70\u001b[0m, in \u001b[0;36mdefault_data_collator\u001b[1;34m(features, return_tensors)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39m# In this function we'll make the assumption that all `features` in the batch\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[39m# have the same attributes.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[39m# So we will look at the first element as a proxy for what attributes exist\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39m# on the whole batch.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[39mif\u001b[39;00m return_tensors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mreturn\u001b[39;00m torch_default_data_collator(features)\n\u001b[0;32m     71\u001b[0m \u001b[39melif\u001b[39;00m return_tensors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m tf_default_data_collator(features)\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\transformers\\data\\data_collator.py:109\u001b[0m, in \u001b[0;36mtorch_default_data_collator\u001b[1;34m(features)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(features[\u001b[39m0\u001b[39m], Mapping):\n\u001b[1;32m--> 109\u001b[0m     features \u001b[39m=\u001b[39m [\u001b[39mvars\u001b[39m(f) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m features]\n\u001b[0;32m    110\u001b[0m first \u001b[39m=\u001b[39m features[\u001b[39m0\u001b[39m]\n\u001b[0;32m    111\u001b[0m batch \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\c.gendron1\\AppData\\Local\\miniconda3\\envs\\playground\\lib\\site-packages\\transformers\\data\\data_collator.py:109\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(features[\u001b[39m0\u001b[39m], Mapping):\n\u001b[1;32m--> 109\u001b[0m     features \u001b[39m=\u001b[39m [\u001b[39mvars\u001b[39;49m(f) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m features]\n\u001b[0;32m    110\u001b[0m first \u001b[39m=\u001b[39m features[\u001b[39m0\u001b[39m]\n\u001b[0;32m    111\u001b[0m batch \u001b[39m=\u001b[39m {}\n",
      "\u001b[1;31mTypeError\u001b[0m: vars() argument must have __dict__ attribute"
     ]
    }
   ],
   "source": [
    "deberta_model = train_transformer(model_path, training_loader, validation_loader, device, lr=1e-5, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
